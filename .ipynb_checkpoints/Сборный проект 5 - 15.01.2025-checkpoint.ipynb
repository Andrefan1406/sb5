{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53728d-ca1f-402b-92bb-83451a4ae235",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CUQuYmMs-mKK",
    "tags": [
     "21a32eca-7494-4096-b202-21be1b7f0a7d"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e15392-d3f2-442d-a8f3-46170cbcc2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch -q\n",
    "!pip install torchvision -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b9abc-62a5-4abd-af0d-7797a2996d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab7ba3-0682-413d-8594-85a894f7e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install contractions -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6966d0-a371-4057-8e1f-b5f2f23c7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import contractions\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1020a",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "1ff1020a"
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-4\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489b26",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "99489b26"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path_1 = r'H:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\train_dataset.csv'\n",
    "    path_2 = r'H:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\CrowdAnnotations.tsv'\n",
    "    path_3 = r'H:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\ExpertAnnotations.tsv'\n",
    "    path_4 = r'H:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\test_queries.csv'\n",
    "    path_5 = os.path.expanduser('~/Downloads/to_upload/train_dataset.csv')\n",
    "    path_6 = os.path.expanduser('~/Downloads/to_upload/CrowdAnnotations.tsv')\n",
    "    path_7 = os.path.expanduser('~/Downloads/to_upload/ExpertAnnotations.tsv')\n",
    "    path_8 = os.path.expanduser('~/Downloads/to_upload/test_queries.csv')\n",
    "\n",
    "    #path_5 = r'J:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\train_dataset.csv'\n",
    "    #path_6 = r'J:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\CrowdAnnotations.tsv'\n",
    "    #path_7 = r'J:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\ExpertAnnotations.tsv'\n",
    "    #path_8 = r'J:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\test_queries.csv'\n",
    "    \n",
    "    try:\n",
    "        train_data = pd.read_csv(path_1)\n",
    "        crowd_data = pd.read_csv(path_2,\n",
    "                                 header=None, \n",
    "                                 sep='\\t', \n",
    "                                 names=['image', 'query_id', 'prc', 'quantity_say_yes', 'quantity_say_no'])\n",
    "        expert_data = pd.read_csv(path_3,\n",
    "                                  header=None,\n",
    "                                  sep='\\t',\n",
    "                                  names=['image', 'query_id', 'grade_1', 'grade_2', 'grade_3'])\n",
    "        test_data = pd.read_csv(path_4, sep='|')\n",
    "    except:\n",
    "        train_data = pd.read_csv(path_5)\n",
    "        crowd_data = pd.read_csv(path_6,\n",
    "                                 header=None, \n",
    "                                 sep='\\t', \n",
    "                                 names=['image', 'query_id', 'prc', 'quantity_say_yes', 'quantity_say_no'])\n",
    "        expert_data = pd.read_csv(path_7,\n",
    "                                  header=None,\n",
    "                                  sep='\\t',\n",
    "                                  names=['image', 'query_id', 'grade_1', 'grade_2', 'grade_3'])\n",
    "        test_data = pd.read_csv(path_8, sep='|')\n",
    "        \n",
    "    return train_data, crowd_data, expert_data, test_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc96b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, crowd_data, expert_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437dc19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce065665",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60fce7-9e27-475f-94ba-24e17cad36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['image'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c55c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crowd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e92cd-70fe-42e8-836a-b2d8ce454f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_data['image'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44277a1-0f24-4ddf-acd8-37b6c4b01da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9863c-6760-44a0-8bc7-9e26efb7107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data['image'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0a0dd-4e8f-4742-b29e-fb20f70dd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=['Unnamed: 0'], axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91627fe-561d-451f-a160-004b127becdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7868dc-3bf9-4244-97fd-f8be5281e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['image'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827863dd-1d76-4a26-ba50-04b9f0835b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data['num_unique_grade'] = expert_data[['grade_1', 'grade_2', 'grade_3']].nunique(axis=1)\n",
    "expert_data = expert_data[expert_data['num_unique_grade'] != 3]\n",
    "expert_data['expert_grade'] = expert_data[['grade_1', 'grade_2', 'grade_3']].mode(axis=1)[0]\n",
    "expert_data['grade_exp'] = expert_data['expert_grade'].apply(lambda x: 1 if x > 2 else 0 )\n",
    "agregate_expert_data = expert_data[['image', 'query_id', 'grade_exp']]\n",
    "agregate_expert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a5321-3936-41f3-8106-94deeb6e8450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crowd_data['crowd_grade'] = crowd_data['prc'].apply(lambda x: 1 if x >0.5 else 0)\n",
    "agregate_crowd_data = crowd_data[['image', 'query_id', 'crowd_grade']]\n",
    "agregate_crowd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c2714-009b-4439-8cda-14acf00089a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(agregate_expert_data, agregate_crowd_data, on=['image', 'query_id'], how='inner')\n",
    "merged_data['final_grade'] = merged_data['grade_exp'] * 0.6 +  merged_data['crowd_grade'] * 0.4\n",
    "merged_data['target'] = merged_data['final_grade'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "final_data = merged_data[['image', 'query_id', 'target']]\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74db06-acb1-4280-923f-24b29bac7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2997309",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "7cbaa861"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352d2cd",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "b352d2cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['query_text'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ef807",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "1d4ef807"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167b804",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "0167b804",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели ResNet-18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Удаление последнего слоя\n",
    "model.eval()  # Перевод модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f370e7d-3fbf-4c01-91c9-bb92170439e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель ResNet-18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Убираем последний слой\n",
    "model.eval()  # Переводим в режим оценки\n",
    "\n",
    "# Простая трансформация для изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Функция для извлечения векторов\n",
    "def extract_vector(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')  # Открытие изображения\n",
    "    image = transform(image).unsqueeze(0)  # Преобразование в формат батча\n",
    "    with torch.no_grad():\n",
    "        vector = model(image).flatten().numpy()  # Преобразование в плоский вектор\n",
    "    return vector\n",
    "\n",
    "# Папка с изображениями\n",
    "image_folder = r'J:\\Мой диск\\1. Практикум\\Сборный проект 5\\dsplus_integrated_project_4\\to_upload\\train_images'\n",
    "data = []\n",
    "\n",
    "# Обработка всех изображений в папке\n",
    "for image_name in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    try:\n",
    "        vector = extract_vector(image_path)  # Извлечение вектора\n",
    "        data.append({'image_name': image_name, 'vector': vector})  # Добавляем в список\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обработки изображения {image_name}: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765b67d-d1ae-4b0d-87d8-f5e06d42281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(data)\n",
    "df_vectors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2ac5d-e386-4cc0-8c20-7f3cac96ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data = np.array(df_vectors['vector'].tolist())  # Преобразуем столбец vector в массив\n",
    "df_new = pd.DataFrame(array_data, columns=[f\"feature_{i}\" for i in range(array_data.shape[1])])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ffd1a-e434-40a6-a501-dc05411a6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_vectors, df_new], axis=1)\n",
    "df_combined.drop(columns=['vector'], axis=1, inplace=True)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea53bf6",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142",
    "id": "aea53bf6"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7584bd",
   "metadata": {
    "cellId": "5f0eae9yldcozrwh01qp0c",
    "id": "cd7584bd"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00960646-78fe-4161-986d-57167adecc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3624c-43f0-4d16-ba70-ab6bfc346997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematize_text(text):\n",
    "    text = text\n",
    "    expanded_text = contractions.fix(text)\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', expanded_text).lower().replace('\\n', ' ').replace('\\r', ' ').replace('  ', ' ')\n",
    "    doc = nlp(cleaned_text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    filtered_tokens = [word for word in lemmas if word not in stop_words]\n",
    "    lemmatized = \" \".join(filtered_tokens)\n",
    "    return lemmatized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c014b-849e-4d1c-998a-424a36986ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_results = []\n",
    "for i in tqdm(range(0, 5822)):\n",
    "    lemmatized = lematize_text(train_data['query_text'][i])\n",
    "    lemmatized_results.append(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13587053-9dd8-4457-a03e-1defa162c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lemmatized_text'] = pd.Series(lemmatized_results)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19030067-ad24-4ae1-bef0-1bbbc37d9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_data['lemmatized_text']\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b33762-e68e-4ca1-9f1b-6bd0311c3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c0ccd",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577",
    "id": "760c0ccd"
   },
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac116b98-d025-466f-bc9b-e387f0ee37a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([train_data, tfidf_df], axis=1)\n",
    "combined_data.drop(columns=['query_text', 'lemmatized_text'], axis=1, inplace=True)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747671f",
   "metadata": {
    "cellId": "n64cmotqegij9arvbc7sxf",
    "id": "b747671f"
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(combined_data, df_combined, left_on='image', right_on='image_name', how='inner')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc5668",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "60bc5668"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723a8ad",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "a723a8ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f870d77",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "2f870d77"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e0c32",
   "metadata": {
    "cellId": "q6sn9kh039f4a6xvu66y7",
    "id": "801e0c32"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab1345a",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "fab1345a"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
